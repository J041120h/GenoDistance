Traceback (most recent call last):
  File "/users/hjiang/GenoDistance/code/Benchmark/pseudobulk_then_directly_scglue.py", line 226, in <module>
    pseudobulk = compute_naive_pseudobulk(
  File "/users/hjiang/GenoDistance/code/Benchmark/pseudobulk_then_directly_scglue.py", line 146, in compute_naive_pseudobulk
    chunk_gpu = torch.from_numpy(chunk_data.astype(np.float32)).to(device)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 62.16 GiB. GPU 0 has a total capacity of 44.43 GiB of which 44.01 GiB is free. Including non-PyTorch memory, this process has 424.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
